# Data Cleaning Agent

A modular and extensible pipeline designed for data cleaning, transformation, and preprocessing, built on top of pandas with support for custom cleaning logic and LLM-assisted handling of ambiguous or unstructured data.
The pipeline automates repetitive tasks such as handling missing values, type enforcement, formatting, and text processing, while also enabling AI-driven decision-making for edge cases.

This project is fully containerized with Docker for portability and ease of deployment. It includes both a backend (FastAPI + agents for pipeline orchestration and LLM integration) and a frontend interface that allows users to upload datasets, configure cleaning rules, and visualize outputs interactively.

---

## ğŸ“‚ Project Structure

```
data-cleaning-agent/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ __pycache__/
â”‚   â”œâ”€â”€ prompts/
â”‚   â”‚   â”œâ”€â”€ __pycache__/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ column_types.py
â”‚   â”‚   â”œâ”€â”€ ordinal_mapping.py
â”‚   â”‚   â”œâ”€â”€ ordinal_nominal.py
â”‚   â”‚   â”œâ”€â”€ preprocssing_prompts.py
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ .dockerignore
â”‚   â”œâ”€â”€ agent.py
â”‚   â”œâ”€â”€ data_cleaning.py
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ llm.py
â”‚   â”œâ”€â”€ main.py
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ sample.csv
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ .dockerignore
â”‚   â”œâ”€â”€ app.py
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ venv/
â”œâ”€â”€ .env
â”œâ”€â”€ .gitignore
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ graph.png

```

## âš™ï¸ Installation

### 1. Clone the repository
```bash
git clone https://github.com/Faiq-Ali10/data-cleaning-agent.git
cd data-cleaning-agent
```

### 2. Setup environment
```bash
Using venv:

python -m venv venv
source venv/bin/activate   # Linux/Mac
venv\Scripts\activate      # Windows

Install dependencies:

pip install -r backend/requirements.txt
pip install -r frontend/requirements.txt
```

### 3. Setup environment variables

Create a .env file in the project root:

store environment variables

### 4. ğŸš€ Usage
Run with Docker Compose
docker-compose up --build


Backend: runs FastAPI app for data cleaning and preprocessing

Frontend: runs a lightweight frontend to interact with the pipeline

Run locally (without Docker)
cd backend
uvicorn main:app

### 5. ğŸ”„ Data Cleaning & Preprocessing Agent

The Agent in backend/agent.py creates a pipeline using StateGraph with the following nodes:

Start Missing Handling â†’ fills missing values in the raw input

LLM Handling â†’ applies LLM-based cleaning or transformations (batch size configurable)

Encoding â†’ encodes categorical features

Final Missing Handling â†’ ensures cleaned output is ready

Pipeline graph is automatically saved as graph.png for visualization.

### 6. ğŸ›  Tech Stack

Python 3.11+

Pandas for data processing

LangGraph for pipeline orchestration

FastAPI for backend API

Docker & Docker Compose for containerization

### 7. ğŸ“Œ Future Improvements

Add unit tests for each pipeline step

Extend LLM handling to support multiple providers

Improve frontend UI for interactive dataset uploads

Add monitoring/logging for pipeline runs

### 8. ğŸ“· Pipeline Graph

The preprocessing pipeline is visualized in graph.png:

##
### ğŸ‘¨â€ğŸ’» Author

Faiq Ali
Data Scientist & ML Engineer