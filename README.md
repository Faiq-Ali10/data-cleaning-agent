# data-cleaning-agent

A modular pipeline for **data cleaning** and **preprocessing** using `pandas`, custom cleaning logic, and LLM-assisted handling.  
This project is containerized with Docker and provides both a **backend** (FastAPI/agents) and a **frontend** interface.

---

## ğŸ“‚ Project Structure

```
data-cleaning-agent/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ __pycache__/
â”‚   â”œâ”€â”€ prompts/
â”‚   â”‚   â”œâ”€â”€ __pycache__/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ column_types.py
â”‚   â”‚   â”œâ”€â”€ ordinal_mapping.py
â”‚   â”‚   â”œâ”€â”€ ordinal_nominal.py
â”‚   â”‚   â”œâ”€â”€ preprocssing_prompts.py
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ .dockerignore
â”‚   â”œâ”€â”€ agent.py
â”‚   â”œâ”€â”€ data_cleaning.py
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ llm.py
â”‚   â”œâ”€â”€ main.py
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ sample.csv
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ .dockerignore
â”‚   â”œâ”€â”€ app.py
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ venv/
â”œâ”€â”€ .env
â”œâ”€â”€ .gitignore
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ graph.png

```

## âš™ï¸ Installation

### 1. Clone the repository
```bash
git clone https://github.com/Faiq-Ali10/data-cleaning-agent.git
cd data-cleaning-agent

2. Setup environment

Using venv:

python -m venv venv
source venv/bin/activate   # Linux/Mac
venv\Scripts\activate      # Windows

Install dependencies:

pip install -r backend/requirements.txt
pip install -r frontend/requirements.txt

3. Setup environment variables

Create a .env file in the project root:

store environment variables

ğŸš€ Usage
Run with Docker Compose
docker-compose up --build


Backend: runs FastAPI app for data cleaning and preprocessing

Frontend: runs a lightweight frontend to interact with the pipeline

Run locally (without Docker)
cd backend
uvicorn main:app

ğŸ”„ Data Cleaning & Preprocessing Agent

The Agent in backend/agent.py creates a pipeline using StateGraph with the following nodes:

Start Missing Handling â†’ fills missing values in the raw input

LLM Handling â†’ applies LLM-based cleaning or transformations (batch size configurable)

Encoding â†’ encodes categorical features

Final Missing Handling â†’ ensures cleaned output is ready

Pipeline graph is automatically saved as graph.png for visualization.

ğŸ›  Tech Stack

Python 3.11+

Pandas for data processing

LangGraph for pipeline orchestration

FastAPI for backend API

Docker & Docker Compose for containerization

ğŸ“Œ Future Improvements

Add unit tests for each pipeline step

Extend LLM handling to support multiple providers

Improve frontend UI for interactive dataset uploads

Add monitoring/logging for pipeline runs

ğŸ“· Pipeline Graph

The preprocessing pipeline is visualized in graph.png:

ğŸ‘¨â€ğŸ’» Author

Faiq Ali
Data Scientist & ML Engineer